## SimpleLLM

Simple extension for interacting with LLMs running locally with `Ollama`

Once installed, edit your `settings.json` to add the config value for the model you wish to use. 

<img width="965" height="578" alt="settings-json" src="https://github.com/user-attachments/assets/17004c8c-c77e-4a02-84f2-fc45af654407" />

Once set up you can use the command palette to run any of the following commands:

1. Ask - ask the LLM a question - any selected text will be passed as context so you can ask about specific code you are working with
2. Generate - ask the LLM to generate some code - generated response will be inserted into the active editor
3. Create - create a new file with code generated by the LLM

