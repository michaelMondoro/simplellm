## SimpleLLM

Simple extension for interacting with LLMs running locally with `Ollama`

Once installed, edit your `settings.json` to add the config value for the model you wish to use. 

![settings.json](./resources/settings-json.png)

Once set up you can use the command palette to run any of the following commands:

1. Ask - ask the LLM a question - any selected text will be passed as context so you can ask about specific code you are working with
2. Generate - ask the LLM to generate some code - generated response will be inserted into the active editor
3. Create - create a new file with code generated by the LLM



